0
00:00:00,000 --> 00:00:00,870


1
00:00:00,870 --> 00:00:02,460
We've seen how streams are made up

2
00:00:02,460 --> 00:00:06,150
of messages that are in turn generated by producers that

3
00:00:06,150 --> 00:00:09,120
can later be read proactively using the range

4
00:00:09,120 --> 00:00:12,150
commands XRANGE and XREVRANGE.

5
00:00:12,150 --> 00:00:14,910
And while ranges are useful for batch processing,

6
00:00:14,910 --> 00:00:16,740
we've also seen how range queries

7
00:00:16,740 --> 00:00:21,910
can be used to process the stream in near-real-time.

8
00:00:21,910 --> 00:00:24,940
Real time consumption is what stream consumers are

9
00:00:24,940 --> 00:00:27,070
all about and in this section, we'll

10
00:00:27,070 --> 00:00:29,110
learn about an even more effective way

11
00:00:29,110 --> 00:00:31,300
to consume our stream in real time.

12
00:00:31,300 --> 00:00:33,980


13
00:00:33,980 --> 00:00:35,870
Let's start the discussion by recalling

14
00:00:35,870 --> 00:00:39,650
how the running sum of natural numbers was implemented.

15
00:00:39,650 --> 00:00:42,980
Every call to range_sum.py

16
00:00:42,980 --> 00:00:46,430
retrieves or initializes a hash storing the last message

17
00:00:46,430 --> 00:00:47,210
ID and sum.

18
00:00:47,210 --> 00:00:49,760


19
00:00:49,760 --> 00:00:52,730
The code then scans all messages in the stream,

20
00:00:52,730 --> 00:00:56,690
sums them up, and stores the results back into the hash.

21
00:00:56,690 --> 00:00:59,600
The amount of actual work done by our code

22
00:00:59,600 --> 00:01:02,720
is dictated by the stream's growth and the number of yet-

23
00:01:02,720 --> 00:01:05,090
to-be-processed messages in it.

24
00:01:05,090 --> 00:01:07,670
As long as we keep calling it fast enough,

25
00:01:07,670 --> 00:01:09,761
our sum will be accurate.

26
00:01:12,650 --> 00:01:16,280
Fast enough is an interesting concept related to time.

27
00:01:16,280 --> 00:01:19,670
Fast enough in our case means faster than any new messages

28
00:01:19,670 --> 00:01:21,560
are added to the stream.

29
00:01:21,560 --> 00:01:22,460
To achieve that.

30
00:01:22,460 --> 00:01:25,940
We could try and wrap the logic inside an infinite loop.

31
00:01:25,940 --> 00:01:29,150
But then most times, we'd just waste calls on empty ranges

32
00:01:29,150 --> 00:01:30,590
and increase the server's load.

33
00:01:33,240 --> 00:01:35,070
Besides being wasteful, this pattern

34
00:01:35,070 --> 00:01:38,700
will limit our ability to scale the consumers significantly

35
00:01:38,700 --> 00:01:40,980
because every consumer will be competing

36
00:01:40,980 --> 00:01:43,740
with all others on the server's resources

37
00:01:43,740 --> 00:01:46,000
by incessantly polling it.

38
00:01:46,000 --> 00:01:49,320
On the other hand, if we call this code any slower,

39
00:01:49,320 --> 00:01:52,620
for example, by sleeping for a second between each call,

40
00:01:52,620 --> 00:01:56,430
not only will our sum's accuracy be off, but also

41
00:01:56,430 --> 00:01:59,670
consider the possibility of a variable workload.

42
00:01:59,670 --> 00:02:01,860
If the producer is jittering, one call

43
00:02:01,860 --> 00:02:04,440
may sum just a couple of numbers where

44
00:02:04,440 --> 00:02:06,600
another may add a big bunch.

45
00:02:06,600 --> 00:02:10,800
This will naturally effect our consumer's code execution time.

46
00:02:10,800 --> 00:02:13,950
And such unpredictabilities could result in bottlenecks

47
00:02:13,950 --> 00:02:15,870
down the road.

48
00:02:15,870 --> 00:02:18,600
So, as a further optimization we may

49
00:02:18,600 --> 00:02:21,900
consider using smaller batches-- that is, the size of one--

50
00:02:21,900 --> 00:02:24,930
and sleeping only when there are no new messages.

51
00:02:24,930 --> 00:02:27,480
This will get us close in terms of accuracy

52
00:02:27,480 --> 00:02:29,880
and runtime predictability, but would still

53
00:02:29,880 --> 00:02:33,300
use wasteful and not so scalable polling logic.

54
00:02:33,300 --> 00:02:36,090
Sleeping is also a non-productive activity,

55
00:02:36,090 --> 00:02:38,040
although it frees the client's cores,

56
00:02:38,040 --> 00:02:40,560
it prevents it from receiving and processing

57
00:02:40,560 --> 00:02:44,910
any new messages that may come in during its slumber.

58
00:02:44,910 --> 00:02:47,430
One-message batches are commonly used

59
00:02:47,430 --> 00:02:51,630
not only because of their semi- predictable processing impact

60
00:02:51,630 --> 00:02:54,180
but also because in many cases messages

61
00:02:54,180 --> 00:02:57,480
can be processed independently one from another

62
00:02:57,480 --> 00:02:59,970
which paves the way to scaling.

63
00:02:59,970 --> 00:03:02,250
We've already met the COUNT sub command

64
00:03:02,250 --> 00:03:05,340
that allows us to restrict the reply from both XRANGE

65
00:03:05,340 --> 00:03:06,850
and XREVRANGE.

66
00:03:06,850 --> 00:03:10,820
It can be used exactly for that.

67
00:03:10,820 --> 00:03:13,100
Now, I'd like to introduce you to another Redis

68
00:03:13,100 --> 00:03:14,440
stream command:

69
00:03:14,440 --> 00:03:15,710
XREAD.

70
00:03:15,710 --> 00:03:19,160
Superficially, XREAD can be used as a drop-in replacement

71
00:03:19,160 --> 00:03:20,660
for XRANGE.

72
00:03:20,660 --> 00:03:24,440
I can, for example, fetch the entire stream like so, just

73
00:03:24,440 --> 00:03:27,390
by providing the name of the stream and the message

74
00:03:27,390 --> 00:03:31,545
ID to begin with, or 0 for the lowest partial message ID.

75
00:03:34,460 --> 00:03:37,670
It is important to note that XREAD does not take

76
00:03:37,670 --> 00:03:39,920
the special IDs "-" or "+".

77
00:03:39,920 --> 00:03:43,850
These are exclusively and solely used by range queries.

78
00:03:43,850 --> 00:03:47,450
XREAD also supports the optional COUNT argument,

79
00:03:47,450 --> 00:03:51,200
so I can use it for iterating the stream at any batch

80
00:03:51,200 --> 00:03:52,670
resolution, just like XRANGE.

81
00:03:55,200 --> 00:03:59,490
In fact, I can modify my code to use XREAD instead of XRANGE

82
00:03:59,490 --> 00:04:01,500
for keeping the running sum while keeping

83
00:04:01,500 --> 00:04:03,500
the rest of the logic pretty much the same.

84
00:04:25,800 --> 00:04:28,740
But, XREAD offers much more than XRANGE does

85
00:04:28,740 --> 00:04:30,720
and the differences, although subtle,

86
00:04:30,720 --> 00:04:32,590
are incredibly important.

87
00:04:32,590 --> 00:04:35,970
The first difference between how XREAD and XRANGE work

88
00:04:35,970 --> 00:04:40,300
is the message ID that XREAD expects.

89
00:04:40,300 --> 00:04:42,700
The ID is actually the last message ID

90
00:04:42,700 --> 00:04:46,000
known to the consumer, which means that Redis will respond

91
00:04:46,000 --> 00:04:50,170
with messages whose IDs are greater than the one provided.

92
00:04:50,170 --> 00:04:53,440
This is unlike XRANGE's inclusive ranges,

93
00:04:53,440 --> 00:04:56,050
which force us to perform complex message ID

94
00:04:56,050 --> 00:05:01,400
arithmetic in order to come up with the next message ID.

95
00:05:01,400 --> 00:05:04,250
Put slightly differently, XREAD's reply

96
00:05:04,250 --> 00:05:07,460
will consist of up to COUNT messages that have

97
00:05:07,460 --> 00:05:09,680
arrived after the requested ID.

98
00:05:09,680 --> 00:05:15,410
I can use either the partial ID 0 or the 0-0 ID

99
00:05:15,410 --> 00:05:18,582
to specify the message prior to the first message

100
00:05:18,582 --> 00:05:19,165
in the stream.

101
00:05:21,860 --> 00:05:23,930
The reply includes the message IDs,

102
00:05:23,930 --> 00:05:25,910
so to continue iterating the stream,

103
00:05:25,910 --> 00:05:28,850
I just copy the last message ID from the reply

104
00:05:28,850 --> 00:05:30,560
to the next call.

105
00:05:30,560 --> 00:05:32,750
That means that the consumer only

106
00:05:32,750 --> 00:05:35,810
needs to track the last ID that it had processed

107
00:05:35,810 --> 00:05:38,300
and carry that from one call to another.

108
00:05:38,300 --> 00:05:39,260
Much simpler.

109
00:05:39,260 --> 00:05:41,725
Cool.

110
00:05:41,725 --> 00:05:43,350
Another difference you may have noticed

111
00:05:43,350 --> 00:05:47,790
is the use of the STREAMS keyword when calling XREAD.

112
00:05:47,790 --> 00:05:51,300
While COUNT is optional, STREAMS isn't.

113
00:05:51,300 --> 00:05:54,750
STREAMS precedes the list of stream key names,

114
00:05:54,750 --> 00:05:58,560
in plural, followed by a list of respective message IDs.

115
00:05:58,560 --> 00:06:02,160
In our example, we've used XREAD to read from a single stream,

116
00:06:02,160 --> 00:06:07,360
but it can actually be used to read from multiple ones.

117
00:06:07,360 --> 00:06:09,700
Because XREAD is a multi-key command

118
00:06:09,700 --> 00:06:12,490
the reply returned differs from that of XRANGE,

119
00:06:12,490 --> 00:06:16,120
in that it includes the stream's key name alongside each list

120
00:06:16,120 --> 00:06:17,620
of returned messages.

121
00:06:17,620 --> 00:06:20,320
This allows us to associate each part of the reply

122
00:06:20,320 --> 00:06:23,060
with the relevant input stream.

123
00:06:23,060 --> 00:06:25,920
Before we move on to what really makes XREAD special,

124
00:06:25,920 --> 00:06:28,310
let's summarize what we've learned so far.

125
00:06:28,310 --> 00:06:31,970
Both XRANGE and XREAD can be used to iterate a stream.

126
00:06:31,970 --> 00:06:35,000
By using the smallest possible batch size, that is,

127
00:06:35,000 --> 00:06:37,610
one message, a consumer's execution time

128
00:06:37,610 --> 00:06:40,810
can be made semi-predictable.

